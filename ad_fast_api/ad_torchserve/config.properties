# 1. 서버 주소 설정
# 추론 API를 제공하는 HTTP 서버 주소 (모든 IP에서 8080 포트로 접근 가능)
inference_address=http://0.0.0.0:8080
# 모델 관리 API를 제공하는 HTTP 서버 주소 (모든 IP에서 8081 포트로 접근 가능)
management_address=http://0.0.0.0:8081
# 메트릭 API를 제공하는 HTTP 서버 주소 (모든 IP에서 8082 포트로 접근 가능)
metrics_address=http://0.0.0.0:8082

# 2. 모델 저장소 및 로딩 설정
# 모델 파일(.mar)이 저장된 디렉토리 경로
model_store=/home/torchserve/model-store
# 서버 시작 시 모든 모델을 자동으로 로드
load_models=all
# 환경 변수를 통한 설정 활성화
enable_envvars_config=true

# 3. 워커 및 작업 큐 설정
# 각 모델당 기본 워커(프로세스) 수 (병렬 처리 능력 결정)
default_workers_per_model=4
# 작업 큐의 최대 크기 (처리 대기 중인 요청 수)
job_queue_size=10
# 워커 프로세스의 시작 포트 번호
initial_worker_port=9000
# 작업 정리 간격 (초)
job_cleanup_interval=2
# 모델 스토어 캐시 정리를 위한 최대 스레드 수
model_store_cache_max_cleanup_thread=2

# 4. 배치 처리 설정
# 기본 배치 크기 (한 번에 처리할 요청 수)
batch_size=4
# 배치 처리 전 최대 대기 시간 (밀리초)
max_batch_delay=200
# 최대 허용 배치 크기
max_batch_size=8

# 5. 타임아웃 설정
# 응답 제한 시간 (초)
default_response_timeout=30
# 모델 로딩 제한 시간 (초)
model_load_timeout=120
# 모델 등록 해제 제한 시간 (초)
unregister_model_timeout=120

# 6. 에러 처리 및 과부하 관리
# 서버 과부하 시 반환할 HTTP 상태 코드 (503: Service Unavailable)
reject_overload_status_code=503
# 작업 큐가 이 비율(%) 이상 차면 새 요청 거부
job_queue_reject_threshold=80
# 서버 종료 시 진행 중인 작업을 완료한 후 종료
use_graceful_stop=true

# 7. 메트릭 및 모니터링 설정
# 메트릭 API 활성화
enable_metrics_api=false

# 8. 네트워크 설정
# Netty 서버의 이벤트 루프 스레드 수 (HTTP 요청 처리)
number_of_netty_threads=6
# Netty 클라이언트의 이벤트 루프 스레드 수 (백엔드 통신)
netty_client_threads=6

# 9. 하드웨어 리소스 설정
# 사용할 GPU 수 (0은 CPU만 사용)
number_of_gpu=0

# 메모리 설정 (주석 해제 및 조정)
maximum_heap_memory=32768